{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "modern-calendar",
   "metadata": {},
   "source": [
    "### Instituto Tecnologico de Costa Rica (ITCR)\n",
    "### Sede Interuniversitaria de Alajuela\n",
    "### Escuela de Computacion\n",
    "### Curso: Inteligencia Artificial\n",
    "### Estudiantes: \n",
    "\n",
    " - Brandon Ledezma Fernández - 2018185574\n",
    " - Walter Morales Vásquez - 2018212846\n",
    "\n",
    "### Profesora:\n",
    " \n",
    " - Maria Auxiliadora Mora\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "friendly-soccer",
   "metadata": {},
   "source": [
    "# Tarea Programada Número 4\n",
    "---\n",
    "#### Introducción:\n",
    "En este trabajo práctico se aplicarán conceptos básicos de aprendizaje automático\n",
    "utilizando redes neuronales recurrentes para resolver problemas que involucran el\n",
    "procesamiento de lenguaje natural.\n",
    "\n",
    "El o los estudiantes deberán realizar dos ejercicios. El primero consiste en implementar\n",
    "una red neuronal recurrente aplicada a un problema de clasificación de textos de opinión\n",
    "sobre prendas de vestir de mujer. El segundo ejercicio consiste en reconocer nombres de\n",
    "entidades en textos (NER, Named-Entity Recognition)\n",
    "\n",
    "El objetivo del trabajo es poner en práctica las habilidades de investigación y el\n",
    "conocimiento adquirido durante el curso sobre redes neuronales por medio de\n",
    "ejercicios prácticos que permitan al estudiante experimentar con el aprendizaje profundo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "unavailable-awareness",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamiento de datos\n",
    "# ==============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ignored-section",
   "metadata": {},
   "source": [
    "## A. Clasificación   de   textos   con   redes   neuronales   recurrentes  LSTM utilizando Pytorch.\n",
    "\n",
    "Se desea que, dado un comentario de revisión de una prenda de vestir, predecir la calificación dada por el comprador. La calificación toma valores enteros entre 1 y 5, donde 1 corresponde a la peor calificación y 5 a la mejor.\n",
    "\n",
    "Datos: Utilice los datos de evaluación de prendas de vestir de mujer disponibles en Kaggle (nicapotato, 2018) para:\n",
    "\n",
    "1. Cargue y prepare los datos para ser introducidos a la red LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "surrounded-badge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>499.500000</td>\n",
       "      <td>910.282000</td>\n",
       "      <td>43.502000</td>\n",
       "      <td>4.194000</td>\n",
       "      <td>0.818000</td>\n",
       "      <td>2.614000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>288.819436</td>\n",
       "      <td>198.919762</td>\n",
       "      <td>12.357374</td>\n",
       "      <td>1.080524</td>\n",
       "      <td>0.386038</td>\n",
       "      <td>5.700131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>249.750000</td>\n",
       "      <td>850.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>499.500000</td>\n",
       "      <td>907.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>749.250000</td>\n",
       "      <td>1060.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>999.000000</td>\n",
       "      <td>1196.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>84.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  Clothing ID          Age       Rating  Recommended IND  \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000      1000.000000   \n",
       "mean    499.500000   910.282000    43.502000     4.194000         0.818000   \n",
       "std     288.819436   198.919762    12.357374     1.080524         0.386038   \n",
       "min       0.000000     2.000000    20.000000     1.000000         0.000000   \n",
       "25%     249.750000   850.000000    35.000000     4.000000         1.000000   \n",
       "50%     499.500000   907.000000    41.000000     5.000000         1.000000   \n",
       "75%     749.250000  1060.000000    52.000000     5.000000         1.000000   \n",
       "max     999.000000  1196.000000    93.000000     5.000000         1.000000   \n",
       "\n",
       "       Positive Feedback Count  \n",
       "count              1000.000000  \n",
       "mean                  2.614000  \n",
       "std                   5.700131  \n",
       "min                   0.000000  \n",
       "25%                   0.000000  \n",
       "50%                   1.000000  \n",
       "75%                   3.000000  \n",
       "max                  84.000000  "
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nRowsRead = 1000\n",
    "\n",
    "# Se carga el archivo con los datos solicitados (defaultofcredit.csv) y se define\n",
    "# a la columna \"default_payment_next_month\" como la objetivo.\n",
    "reviews = pd.read_csv('./data/Womens Clothing E-Commerce Reviews.csv', delimiter=',', nrows=nRowsRead)\n",
    "#reviews = pd.read_csv('./data/a.csv')\n",
    "reviews.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "democratic-cable",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Absolutely wonderful - silky and sexy and comf...\n",
       "1      Love this dress!  it's sooo pretty.  i happene...\n",
       "2      I had such high hopes for this dress and reall...\n",
       "3      I love, love, love this jumpsuit. it's fun, fl...\n",
       "4      This shirt is very flattering to all due to th...\n",
       "                             ...                        \n",
       "995    Received these as a christmas gift from my dau...\n",
       "996    Every year around this time, our beloved retai...\n",
       "997    I tried on this sweater in the store and immed...\n",
       "998    Super soft and comfortable. runs a little larg...\n",
       "999    Wear the collar down & it favors grace kelly. ...\n",
       "Name: Review Text, Length: 958, dtype: object"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete missing observations for following variables\n",
    "# for x in [\"Clothing ID\",\"Age\",\"Title\",\"Review Text\",\"Rating\",\"Recommended IND\",\"Positive Feedback Count\",\"Division Name\",\"Department Name\",\"Class Name\"]:\n",
    "#     reviews = reviews[reviews[x].notnull()]\n",
    "    \n",
    "# X = reviews.drop(columns = reviews.columns[3:5])\n",
    "# X = pd.get_dummies(X)\n",
    "# y = reviews['Review Text']\n",
    "# y = [elem.split() for elem in y]\n",
    "\n",
    "#reviews['Rating'] = reviews[(reviews['Rating'] >= 1)  (reviews['Rating'] <= 5)]\n",
    "\n",
    "for x in [\"Review Text\",\"Rating\"]:\n",
    "     reviews = reviews[reviews[x].notnull()]\n",
    "\n",
    "X = reviews['Review Text']\n",
    "#X = [elem.split() for elem in X]\n",
    "y = reviews['Rating']\n",
    "\n",
    "# word_to_ix = {}\n",
    "# for review in X:\n",
    "# #     if review not in word_to_ix:\n",
    "# #         word_to_ix[review] = len(word_to_ix)\n",
    "#     for word in review:\n",
    "#         if word not in word_to_ix:\n",
    "#             word_to_ix[word] = len(word_to_ix)\n",
    "\n",
    "ratings = [1, 2, 3, 4, 5]\n",
    "            \n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "paperback-green",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-229-6ea927cc6e88>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-229-6ea927cc6e88>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    pip3 install tensorflow\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip3 install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "experienced-firewall",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-228-9953f7e180cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_on_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X)\n",
    "\n",
    "sentence_sq = tokenizer.texts_to_sequences(X)\n",
    "\n",
    "print(sentence_sq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detected-likelihood",
   "metadata": {},
   "source": [
    "2. Utilizando PyTorch defina una red recurrente LSTM para procesar el conjunto de datos y clasificar los comentarios de usuario. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "light-nebraska",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "output with shape [2] doesn't match the broadcast shape [2, 2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-201-450b27e8011b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mtensor_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;31m#max_values(torch.tensor([[1,2,1,5,9]]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-201-450b27e8011b>\u001b[0m in \u001b[0;36mtensor_mean\u001b[0;34m(input)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#requires_grad=False) grad_fn=input.grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: output with shape [2] doesn't match the broadcast shape [2, 2]"
     ]
    }
   ],
   "source": [
    "# def tensor_mean(input):\n",
    "    \n",
    "#     output = torch.tensor(np.zeros(input[0].size(0)))\n",
    "#     #output = input.clone().detach()\n",
    "#     #output = output[torch.arange(output.size(0))==0]\n",
    "#     #print('output', output)\n",
    "# #     print('output', output)\n",
    "# #     print('output', output[0])\n",
    "#     #print('input', input)\n",
    "# #     print('input[0].size(0)', input[0].size(0))\n",
    "    \n",
    "#     for i in range(input.size(0)):\n",
    "#         for j in range(input[i].size(0)):\n",
    "#             output[j] += input[i][j]\n",
    "            \n",
    "#     for i in range(output.size(0)):\n",
    "#         output[i] /= input.size(0)\n",
    "    \n",
    "#     return output.data.copy_(input.data)\n",
    "#     return torch.tensor([output.tolist()], grad_fn=input.grad_fn)#requires_grad=False) grad_fn=input.grad\n",
    "\n",
    "# # Funciones utilitarias\n",
    "\n",
    "# def max_values(x):\n",
    "#     # Retorna el valor máximo y en índice o la posición del valor en un vector x.\n",
    "#     # Parámetros: \n",
    "#     #    x: vector con los datos. \n",
    "#     # Salida: \n",
    "#     #    out: valor \n",
    "#     #    inds: índice\n",
    "#     out, inds = torch.max(x,dim=1)   \n",
    "#     return out, inds\n",
    "\n",
    "# tensor_mean(torch.tensor([[1,1],[2,2]]))\n",
    "# #max_values(torch.tensor([[1,2,1,5,9]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "intimate-number",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input tensor([[1, 1],\n",
      "        [3, 3]])\n",
      "tensor([[2., 2.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "def tensor_mean(input):\n",
    "    \n",
    "    #output = torch.tensor(np.zeros(input[0].size(0)))\n",
    "    print('input', input)\n",
    "    #input?\n",
    "    output = input.clone().detach()\n",
    "    #output.grad_fn.data.copy_(input.grad_fn.data)\n",
    "    \n",
    "    input = input[torch.arange(input.size(0))==0].double()\n",
    "#     print('output', output)\n",
    "#     print('input', input)\n",
    "#     print('output', output)\n",
    "#     print('output', output[0])\n",
    "#     print('input[0].size(0)', input[0].size(0))\n",
    "    \n",
    "    for i in range(1, output.size(0)):\n",
    "        for j in range(output[i].size(0)):\n",
    "            input[0][j] += output[i][j]\n",
    "            \n",
    "    for i in range(input[0].size(0)):\n",
    "        input[0][i] /= output.size(0)\n",
    "    return input\n",
    "    #return torch.tensor([output.tolist()], grad_fn=input.grad_fn)#requires_grad=False) grad_fn=input.grad\n",
    "\n",
    "# Funciones utilitarias\n",
    "\n",
    "def max_values(x):\n",
    "    # Retorna el valor máximo y en índice o la posición del valor en un vector x.\n",
    "    # Parámetros: \n",
    "    #    x: vector con los datos. \n",
    "    # Salida: \n",
    "    #    out: valor \n",
    "    #    inds: índice\n",
    "    out, inds = torch.max(x,dim=1)   \n",
    "    return out, inds\n",
    "\n",
    "print(tensor_mean(torch.tensor([[1,1],[3,3]])))\n",
    "#max_values(torch.tensor([[1,2,1,5,9]]))\n",
    "\n",
    "def clone_vs_deepcopy(x):\n",
    "    import copy\n",
    "    import torch\n",
    "\n",
    "    x_clone = x.clone()\n",
    "    x_deep_copy = copy.deepcopy(x)\n",
    "    #\n",
    "    x.mul_(-1)\n",
    "    print(f'x = {x}')\n",
    "    print(f'x_clone = {x_clone}')\n",
    "    print(f'x_deep_copy = {x_deep_copy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "approximate-adoption",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición del modelo\n",
    "\n",
    "# El modelo es una clase que debe heredar de nn.Module\n",
    "class LSTMTagger(nn.Module):\n",
    "    \n",
    "    # Incialización del modelo\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # Primero se pasa la entrada a través de una capa Embedding. \n",
    "        # Esta capa construye una representación de los tokens de \n",
    "        # un texto donde las palabras que tienen el mismo significado \n",
    "        # tienen una representación similar.\n",
    "        \n",
    "        # Esta capa captura mejor el contexto y son espacialmente \n",
    "        # más eficientes que las representaciones vectoriales (one-hot vector).\n",
    "        # En Pytorch, se usa el módulo nn.Embedding para crear esta capa, \n",
    "        # que toma el tamaño del vocabulario y la longitud deseada del vector \n",
    "        # de palabras como entrada. \n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # El LSTM toma word_embeddings como entrada y genera estados ocultos\n",
    "        # con dimensionalidad hidden_dim.  \n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "\n",
    "        # La capa lineal mapea el espacio de estado oculto \n",
    "        # al espacio de etiquetas\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        # Pase hacia adelante de la red. \n",
    "        # Parámetros:\n",
    "        #    sentence: la oración a procesar\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        \n",
    "        print('embeds', embeds)\n",
    "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
    "        \n",
    "        print('lstm_out', lstm_out)\n",
    "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "        print('tag_space', tag_space)\n",
    "        \n",
    "        # Se utiliza softmax para devolver un peso por etiqueta\n",
    "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "        print('tag_scores', tag_scores)\n",
    "        print('torch.mean(tag_scores,0)', torch.mean(tag_scores,0))\n",
    "        return torch.mean(tag_scores,0)\n",
    "\n",
    "# Instanciación del modelo, definición de la función de pérdida y del optimizador   \n",
    "\n",
    "# Hiperparámetros de la red\n",
    "# Valores generalmente altos (32 o 64 dimensiones).\n",
    "# Se definen pequeños, para ver cómo cambian los pesos durante el entrenamiento.\n",
    "\n",
    "EMBEDDING_DIM = 6\n",
    "HIDDEN_DIM = 6\n",
    "\n",
    "# Instancia del modelo\n",
    "model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix), len(ratings)) # len([1,2,3,4,5]))\n",
    "\n",
    "# Función de pérdida: Negative Log Likelihood Loss (NLLL). \n",
    "# Útil para problemas de clasificacion con C clases.\n",
    "loss_function = nn.NLLLoss()\n",
    "\n",
    "# Optimizador Stochastic Gradient Descent  \n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriented-kentucky",
   "metadata": {},
   "source": [
    "3. Separe las muestras en datos de entrenamiento y evaluación y entrene el modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "traditional-excitement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Absolutely', 'wonderful', '-', 'silky', 'and', 'sexy', 'and', 'comfortable'] [4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Absolutely': 0,\n",
       " 'wonderful': 1,\n",
       " '-': 2,\n",
       " 'silky': 3,\n",
       " 'and': 4,\n",
       " 'sexy': 5,\n",
       " 'comfortable': 6,\n",
       " 'Love': 7,\n",
       " 'this': 8,\n",
       " 'dress!': 9,\n",
       " \"it's\": 10,\n",
       " 'sooo': 11,\n",
       " 'pretty.': 12,\n",
       " 'i': 13,\n",
       " 'happened': 14,\n",
       " 'to': 15,\n",
       " 'find': 16,\n",
       " 'it': 17,\n",
       " 'in': 18,\n",
       " 'a': 19,\n",
       " 'store,': 20,\n",
       " \"i'm\": 21,\n",
       " 'glad': 22,\n",
       " 'did': 23,\n",
       " 'bc': 24,\n",
       " 'never': 25,\n",
       " 'would': 26,\n",
       " 'have': 27,\n",
       " 'ordered': 28,\n",
       " 'online': 29,\n",
       " 'petite.': 30,\n",
       " 'bought': 31,\n",
       " 'petite': 32,\n",
       " 'am': 33,\n",
       " '5\\'8\".': 34,\n",
       " 'love': 35,\n",
       " 'the': 36,\n",
       " 'length': 37,\n",
       " 'on': 38,\n",
       " 'me-': 39,\n",
       " 'hits': 40,\n",
       " 'just': 41,\n",
       " 'little': 42,\n",
       " 'below': 43,\n",
       " 'knee.': 44,\n",
       " 'definitely': 45,\n",
       " 'be': 46,\n",
       " 'true': 47,\n",
       " 'midi': 48,\n",
       " 'someone': 49,\n",
       " 'who': 50,\n",
       " 'is': 51,\n",
       " 'truly': 52,\n",
       " 'I': 53,\n",
       " 'had': 54,\n",
       " 'such': 55,\n",
       " 'high': 56,\n",
       " 'hopes': 57,\n",
       " 'for': 58,\n",
       " 'dress': 59,\n",
       " 'really': 60,\n",
       " 'wanted': 61,\n",
       " 'work': 62,\n",
       " 'me.': 63,\n",
       " 'initially': 64,\n",
       " 'small': 65,\n",
       " '(my': 66,\n",
       " 'usual': 67,\n",
       " 'size)': 68,\n",
       " 'but': 69,\n",
       " 'found': 70,\n",
       " 'outrageously': 71,\n",
       " 'small.': 72,\n",
       " 'so': 73,\n",
       " 'fact': 74,\n",
       " 'that': 75,\n",
       " 'could': 76,\n",
       " 'not': 77,\n",
       " 'zip': 78,\n",
       " 'up!': 79,\n",
       " 'reordered': 80,\n",
       " 'medium,': 81,\n",
       " 'which': 82,\n",
       " 'was': 83,\n",
       " 'ok.': 84,\n",
       " 'overall,': 85,\n",
       " 'top': 86,\n",
       " 'half': 87,\n",
       " 'fit': 88,\n",
       " 'nicely,': 89,\n",
       " 'bottom': 90,\n",
       " 'very': 91,\n",
       " 'tight': 92,\n",
       " 'under': 93,\n",
       " 'layer': 94,\n",
       " 'several': 95,\n",
       " 'somewhat': 96,\n",
       " 'cheap': 97,\n",
       " '(net)': 98,\n",
       " 'over': 99,\n",
       " 'layers.': 100,\n",
       " 'imo,': 101,\n",
       " 'major': 102,\n",
       " 'design': 103,\n",
       " 'flaw': 104,\n",
       " 'net': 105,\n",
       " 'sewn': 106,\n",
       " 'directly': 107,\n",
       " 'into': 108,\n",
       " 'zipper': 109,\n",
       " 'c': 110,\n",
       " 'love,': 111,\n",
       " 'jumpsuit.': 112,\n",
       " 'fun,': 113,\n",
       " 'flirty,': 114,\n",
       " 'fabulous!': 115,\n",
       " 'every': 116,\n",
       " 'time': 117,\n",
       " 'wear': 118,\n",
       " 'it,': 119,\n",
       " 'get': 120,\n",
       " 'nothing': 121,\n",
       " 'great': 122,\n",
       " 'compliments!': 123,\n",
       " 'This': 124,\n",
       " 'shirt': 125,\n",
       " 'flattering': 126,\n",
       " 'all': 127,\n",
       " 'due': 128,\n",
       " 'adjustable': 129,\n",
       " 'front': 130,\n",
       " 'tie.': 131,\n",
       " 'perfect': 132,\n",
       " 'with': 133,\n",
       " 'leggings': 134,\n",
       " 'sleeveless': 135,\n",
       " 'pairs': 136,\n",
       " 'well': 137,\n",
       " 'any': 138,\n",
       " 'cardigan.': 139,\n",
       " 'shirt!!!': 140,\n",
       " 'tracy': 141,\n",
       " 'reese': 142,\n",
       " 'dresses,': 143,\n",
       " 'one': 144,\n",
       " '5': 145,\n",
       " 'feet': 146,\n",
       " 'tall': 147,\n",
       " 'usually': 148,\n",
       " '0p': 149,\n",
       " 'brand.': 150,\n",
       " 'pretty': 151,\n",
       " 'out': 152,\n",
       " 'of': 153,\n",
       " 'package': 154,\n",
       " 'its': 155,\n",
       " 'lot': 156,\n",
       " 'dress.': 157,\n",
       " 'skirt': 158,\n",
       " 'long': 159,\n",
       " 'full': 160,\n",
       " 'overwhelmed': 161,\n",
       " 'my': 162,\n",
       " 'frame.': 163,\n",
       " 'stranger': 164,\n",
       " 'alterations,': 165,\n",
       " 'shortening': 166,\n",
       " 'narrowing': 167,\n",
       " 'take': 168,\n",
       " 'away': 169,\n",
       " 'from': 170,\n",
       " 'embellishment': 171,\n",
       " 'garment.': 172,\n",
       " 'color': 173,\n",
       " 'idea': 174,\n",
       " 'style': 175,\n",
       " 'returned': 176,\n",
       " 'aded': 177,\n",
       " 'basket': 178,\n",
       " 'at': 179,\n",
       " 'hte': 180,\n",
       " 'last': 181,\n",
       " 'mintue': 182,\n",
       " 'see': 183,\n",
       " 'what': 184,\n",
       " 'look': 185,\n",
       " 'like': 186,\n",
       " 'person.': 187,\n",
       " '(store': 188,\n",
       " 'pick': 189,\n",
       " 'up).': 190,\n",
       " 'went': 191,\n",
       " 'teh': 192,\n",
       " 'darkler': 193,\n",
       " 'only': 194,\n",
       " 'because': 195,\n",
       " 'pale': 196,\n",
       " ':-)': 197,\n",
       " 'gorgeous,': 198,\n",
       " 'turns': 199,\n",
       " 'mathced': 200,\n",
       " 'everythiing': 201,\n",
       " 'trying': 202,\n",
       " 'prefectly.': 203,\n",
       " 'baggy': 204,\n",
       " 'me': 205,\n",
       " 'xs': 206,\n",
       " 'msallet': 207,\n",
       " 'size': 208,\n",
       " '(bummer,': 209,\n",
       " 'no': 210,\n",
       " 'petite).': 211,\n",
       " 'decided': 212,\n",
       " 'jkeep': 213,\n",
       " 'though,': 214,\n",
       " 'as': 215,\n",
       " 'said,': 216,\n",
       " 'matvehd': 217,\n",
       " 'everything.': 218,\n",
       " 'ejans,': 219,\n",
       " 'pants,': 220,\n",
       " '3': 221,\n",
       " 'skirts': 222,\n",
       " 'waas': 223,\n",
       " '(of': 224,\n",
       " ']kept': 225,\n",
       " ')': 226,\n",
       " 'oops.': 227,\n",
       " 'carbon': 228,\n",
       " 'store': 229,\n",
       " 'up,': 230,\n",
       " 'ton': 231,\n",
       " 'stuff': 232,\n",
       " '(as': 233,\n",
       " 'always)': 234,\n",
       " 'try': 235,\n",
       " 'used': 236,\n",
       " 'pair': 237,\n",
       " '(skirts': 238,\n",
       " 'pants).': 239,\n",
       " 'everything': 240,\n",
       " 'it.': 241,\n",
       " 'nice': 242,\n",
       " 'charcoal': 243,\n",
       " 'shimmer,': 244,\n",
       " 'pencil': 245,\n",
       " 'skirts,': 246,\n",
       " 'flare': 247,\n",
       " 'etc.': 248,\n",
       " 'compaint': 249,\n",
       " 'bit': 250,\n",
       " 'big,': 251,\n",
       " 'sleeves': 252,\n",
       " 'are': 253,\n",
       " \"doesn't\": 254,\n",
       " 'go': 255,\n",
       " 'also': 256,\n",
       " 'loose': 257,\n",
       " 'me,': 258,\n",
       " 'xxs...': 259,\n",
       " 'kept': 260,\n",
       " 'wil': 261,\n",
       " 'ldecide': 262,\n",
       " 'later': 263,\n",
       " 'since': 264,\n",
       " 'light': 265,\n",
       " 'already': 266,\n",
       " 'sold': 267,\n",
       " 'smallest': 268,\n",
       " 'size...': 269,\n",
       " 'an': 270,\n",
       " 'runs': 271,\n",
       " 'snug': 272,\n",
       " 'bust': 273,\n",
       " 'up': 274,\n",
       " 'size.': 275,\n",
       " 'feminine': 276,\n",
       " 'retailer': 277,\n",
       " 'flair': 278,\n",
       " 'style.': 279,\n",
       " \"I'm\": 280,\n",
       " '5\"5\\'': 281,\n",
       " '125': 282,\n",
       " 'lbs.': 283,\n",
       " 's': 284,\n",
       " 'make': 285,\n",
       " 'sure': 286,\n",
       " \"wasn't\": 287,\n",
       " 'too': 288,\n",
       " 'long.': 289,\n",
       " 'typically': 290,\n",
       " 'regular': 291,\n",
       " 'dresses.': 292,\n",
       " 'if': 293,\n",
       " \"you're\": 294,\n",
       " 'less': 295,\n",
       " 'busty': 296,\n",
       " '(34b': 297,\n",
       " 'cup': 298,\n",
       " 'or': 299,\n",
       " 'smaller),': 300,\n",
       " 'will': 301,\n",
       " 'you': 302,\n",
       " 'perfectly': 303,\n",
       " '(snug,': 304,\n",
       " 'tight).': 305,\n",
       " 'party,': 306,\n",
       " 'down': 307,\n",
       " 'work.': 308,\n",
       " 'tulle': 309,\n",
       " 'longer': 310,\n",
       " 'then': 311,\n",
       " 'fabric': 312,\n",
       " 'underneath.': 313,\n",
       " 'Dress': 314,\n",
       " 'esp': 315,\n",
       " 'where': 316,\n",
       " 'area': 317,\n",
       " 'runs.': 318,\n",
       " 'sp': 319,\n",
       " 'fits': 320,\n",
       " 'tight!': 321,\n",
       " 'material': 322,\n",
       " 'looks': 323,\n",
       " 'feels': 324,\n",
       " 'even': 325,\n",
       " 'pulling': 326,\n",
       " 'cause': 327,\n",
       " 'rip': 328,\n",
       " 'fabric.': 329,\n",
       " 'disappointed': 330,\n",
       " 'going': 331,\n",
       " 'christmas': 332,\n",
       " 'year!': 333,\n",
       " 'needless': 334,\n",
       " 'say': 335,\n",
       " 'back.': 336,\n",
       " 'perfection!': 337,\n",
       " 'flattering.': 338,\n",
       " 'More': 339,\n",
       " 'more': 340,\n",
       " 'myself': 341,\n",
       " 'reliant': 342,\n",
       " 'reviews': 343,\n",
       " 'written': 344,\n",
       " 'by': 345,\n",
       " 'savvy': 346,\n",
       " 'shoppers': 347,\n",
       " 'before': 348,\n",
       " 'most': 349,\n",
       " 'past,': 350,\n",
       " 'they': 351,\n",
       " 'right': 352,\n",
       " 'their': 353,\n",
       " 'estimation': 354,\n",
       " 'product.': 355,\n",
       " 'case': 356,\n",
       " 'dress-if': 357,\n",
       " 'been': 358,\n",
       " 'reveiws-i': 359,\n",
       " 'doubt': 360,\n",
       " 'tried': 361,\n",
       " 'this.': 362,\n",
       " 'beautifully': 363,\n",
       " 'made,': 364,\n",
       " 'lined': 365,\n",
       " 'reminiscent': 366,\n",
       " 'old': 367,\n",
       " 'quality.': 368,\n",
       " 'solid': 369,\n",
       " 'periwinkle-colored': 370,\n",
       " 'matches': 371,\n",
       " 'outer': 372,\n",
       " 'print.': 373,\n",
       " 'tts': 374,\n",
       " 'form-fitting.': 375,\n",
       " 'falls': 376,\n",
       " 'above': 377,\n",
       " 'knee': 378,\n",
       " 'does': 379,\n",
       " 'rid': 380,\n",
       " 'Bought': 381,\n",
       " 'black': 382,\n",
       " 'larkspur': 383,\n",
       " \"didn't\": 384,\n",
       " 'bother': 385,\n",
       " 'lining': 386,\n",
       " 'portion': 387,\n",
       " '(grrrrrrrrrrr).': 388,\n",
       " 'stats': 389,\n",
       " '34a-28/29-36': 390,\n",
       " 'smoothly': 391,\n",
       " 'around': 392,\n",
       " 'chest': 393,\n",
       " 'flowy': 394,\n",
       " 'lower': 395,\n",
       " 'half,': 396,\n",
       " 'running': 397,\n",
       " 'big.': 398,\n",
       " 'straps': 399,\n",
       " 'easily': 400,\n",
       " 'nightwear': 401,\n",
       " 'too.': 402,\n",
       " '5\\'6\"': 403,\n",
       " 'came': 404,\n",
       " 'knees.': 405,\n",
       " 'choice': 406,\n",
       " 'holiday': 407,\n",
       " 'gatherings.': 408,\n",
       " 'grazes': 409,\n",
       " 'conservative': 410,\n",
       " 'enough': 411,\n",
       " 'office': 412,\n",
       " 'related': 413,\n",
       " '2/4': 414,\n",
       " 'bust.': 415,\n",
       " 'opinion': 416,\n",
       " 'those': 417,\n",
       " 'larger': 418,\n",
       " 'busts': 419,\n",
       " '(but': 420,\n",
       " 'perhaps': 421,\n",
       " 'waist': 422,\n",
       " 'big).': 423,\n",
       " 'problem': 424,\n",
       " 'fabrics': 425,\n",
       " 'terrible.': 426,\n",
       " 'delicate': 427,\n",
       " 'netting': 428,\n",
       " 'type': 429,\n",
       " 'got': 430,\n",
       " 'stuck': 431,\n",
       " 'took': 432,\n",
       " 'these': 433,\n",
       " 'them': 434,\n",
       " 'badly,': 435,\n",
       " 'tell': 436,\n",
       " 'put': 437,\n",
       " \"wouldn't.\": 438,\n",
       " 'hour-glass': 439,\n",
       " 'figure.': 440,\n",
       " 'straight': 441,\n",
       " 'down.': 442,\n",
       " 'way': 443,\n",
       " 'body': 444,\n",
       " 'shape': 445,\n",
       " 'sized': 446,\n",
       " 'still': 447,\n",
       " 'roomy': 448,\n",
       " 'hips': 449,\n",
       " 'nice.': 450,\n",
       " 'sturdy,': 451,\n",
       " 'linen-like': 452,\n",
       " 'fabric,': 453,\n",
       " 'color,': 454,\n",
       " 'made.': 455,\n",
       " 'hope': 456,\n",
       " 'happy!': 457,\n",
       " 'Material': 458,\n",
       " 'leg': 459,\n",
       " 'opening': 460,\n",
       " 'large.': 461,\n",
       " \"5'1\": 462,\n",
       " '(100#)': 463,\n",
       " 'ankle.': 464,\n",
       " 'hem': 465,\n",
       " 'line': 466,\n",
       " 'ankle,': 467,\n",
       " 'pleats': 468,\n",
       " 'fluffy,': 469,\n",
       " 'think': 470,\n",
       " 'can': 471,\n",
       " 'imagine': 472,\n",
       " 'look.': 473,\n",
       " 'least': 474,\n",
       " 'average': 475,\n",
       " 'height': 476,\n",
       " 'taller,': 477,\n",
       " 'may': 478,\n",
       " 'good': 479,\n",
       " 'you.': 480,\n",
       " 'Took': 481,\n",
       " 'chance': 482,\n",
       " 'blouse': 483,\n",
       " 'did.': 484,\n",
       " 'crazy': 485,\n",
       " 'about': 486,\n",
       " 'how': 487,\n",
       " 'photographed': 488,\n",
       " 'model.': 489,\n",
       " 'paired': 490,\n",
       " 'whit': 491,\n",
       " 'white': 492,\n",
       " 'pants': 493,\n",
       " 'worked': 494,\n",
       " 'perfectly.': 495,\n",
       " 'crisp': 496,\n",
       " 'clean': 497,\n",
       " 'describe': 498,\n",
       " 'launders': 499,\n",
       " 'well.': 500,\n",
       " 'great.': 501,\n",
       " 'drape': 502,\n",
       " 'perfect.': 503,\n",
       " 'tucked': 504,\n",
       " \"can't\": 505,\n",
       " 'wrong.': 506,\n",
       " 'A': 507,\n",
       " 'flattering,': 508,\n",
       " 'super': 509,\n",
       " 'cozy': 510,\n",
       " 'coat.': 511,\n",
       " 'cold,': 512,\n",
       " 'dry': 513,\n",
       " 'days': 514,\n",
       " 'jeans': 515,\n",
       " 'dressier': 516,\n",
       " 'outfit.': 517,\n",
       " \"5'\": 518,\n",
       " \"5'',\": 519,\n",
       " '135': 520,\n",
       " 'feel': 521,\n",
       " 'looking': 522,\n",
       " 'something': 523,\n",
       " 'different,': 524,\n",
       " 'new': 525,\n",
       " \"year's\": 526,\n",
       " 'eve.': 527,\n",
       " 'chested': 528,\n",
       " 'form': 529,\n",
       " 'fitting': 530,\n",
       " 'once': 531,\n",
       " 'steamed': 532,\n",
       " 'tulle,': 533,\n",
       " 'perfect!': 534,\n",
       " 'xsp.': 535,\n",
       " 'If': 536,\n",
       " 'product': 537,\n",
       " 'petite,': 538,\n",
       " 'tailor': 539,\n",
       " 'do': 540,\n",
       " 'simple': 541,\n",
       " 'fix': 542,\n",
       " 'that.': 543,\n",
       " 'nicely!': 544,\n",
       " \"5'4,\": 545,\n",
       " '130lb': 546,\n",
       " 'pregnant': 547,\n",
       " 'bough': 548,\n",
       " 't': 549,\n",
       " 'medium': 550,\n",
       " 'grow': 551,\n",
       " 'into.': 552,\n",
       " 'tie': 553,\n",
       " 'back': 554,\n",
       " 'provides': 555,\n",
       " 'some': 556,\n",
       " 'flexibility': 557,\n",
       " 'fitting.': 558,\n",
       " 'upset': 559,\n",
       " 'price': 560,\n",
       " 'dress,': 561,\n",
       " 'thought': 562,\n",
       " 'embroidered!': 563,\n",
       " 'no,': 564,\n",
       " 'print': 565,\n",
       " 'cried': 566,\n",
       " 'when': 567,\n",
       " 'opened': 568,\n",
       " 'box.': 569,\n",
       " 'ver': 570,\n",
       " 'size,': 571,\n",
       " 'tad': 572,\n",
       " 'big': 573,\n",
       " 'tiny,': 574,\n",
       " 'vibrant.': 575,\n",
       " 'unique.': 576,\n",
       " 'poofy.': 577,\n",
       " 'keep': 578,\n",
       " 'forth': 579,\n",
       " 'mainly': 580,\n",
       " 'price,': 581,\n",
       " 'although': 582,\n",
       " 'quality': 583,\n",
       " 'there.': 584,\n",
       " 'except': 585,\n",
       " 'wish': 586,\n",
       " 'were': 587,\n",
       " 'emb': 588,\n",
       " 'First': 589,\n",
       " 'all,': 590,\n",
       " 'pullover': 591,\n",
       " 'styling.': 592,\n",
       " 'there': 593,\n",
       " 'side': 594,\n",
       " 'zipper.': 595,\n",
       " \"wouldn't\": 596,\n",
       " 'purchased': 597,\n",
       " 'knew': 598,\n",
       " 'large': 599,\n",
       " 'zippers': 600,\n",
       " 'next': 601,\n",
       " 'impossible': 602,\n",
       " 'second': 603,\n",
       " 'slip': 604,\n",
       " 'has': 605,\n",
       " 'awkward': 606,\n",
       " 'described': 607,\n",
       " 'as.': 608,\n",
       " 'sadly': 609,\n",
       " 'returning,': 610,\n",
       " 'exchange': 611,\n",
       " 'for!': 612,\n",
       " 'Cute': 613,\n",
       " 'tts.': 614,\n",
       " 'waisted.': 615,\n",
       " \"5'9\": 616,\n",
       " 'height.': 617,\n",
       " 'dont': 618,\n",
       " 'cheap.': 619,\n",
       " 'appears': 620,\n",
       " 'pictured.': 621,\n",
       " 'first': 622,\n",
       " 'saw': 623,\n",
       " 'see-through': 624,\n",
       " 'need': 625,\n",
       " 'leggings.': 626,\n",
       " 'slip,': 627,\n",
       " 'wore': 628,\n",
       " 'back,': 629,\n",
       " 'rocked': 630,\n",
       " 'wedges.': 631,\n",
       " 'vest.': 632,\n",
       " 'careful': 633,\n",
       " 'buttons.': 634,\n",
       " \"haven't\": 635,\n",
       " 'fall': 636,\n",
       " 'off': 637,\n",
       " 'yet,': 638,\n",
       " 'will.': 639,\n",
       " 'overall': 640,\n",
       " 'occasion': 641,\n",
       " 'fun': 642,\n",
       " 'wear!': 643,\n",
       " 'Loved': 644,\n",
       " 'material,': 645,\n",
       " 'didnt': 646,\n",
       " 'both': 647,\n",
       " 'medium.': 648,\n",
       " 'im': 649,\n",
       " '5\\'5\"': 650,\n",
       " 'atleast': 651,\n",
       " '5\"': 652,\n",
       " 'feet.': 653,\n",
       " 'gaps': 654,\n",
       " 'much': 655,\n",
       " 'wider': 656,\n",
       " 'than': 657,\n",
       " 'felt': 658,\n",
       " 'fell': 659,\n",
       " 'flat.': 660,\n",
       " 'returned.': 661,\n",
       " 'med': 662,\n",
       " 'better.': 663,\n",
       " '36d': 664,\n",
       " '30': 665,\n",
       " 'waiting': 666,\n",
       " 'sweater': 667,\n",
       " 'coat': 668,\n",
       " 'ship': 669,\n",
       " 'weeks': 670,\n",
       " 'excited': 671,\n",
       " 'arrive.': 672,\n",
       " 'made': 673,\n",
       " 'short': 674,\n",
       " 'squat.': 675,\n",
       " 'wide': 676,\n",
       " '(although': 677,\n",
       " 'long).': 678,\n",
       " 'weight': 679,\n",
       " \"don't\": 680,\n",
       " 'layerng': 681,\n",
       " 'buttons': 682,\n",
       " 'moved': 683,\n",
       " 'three': 684,\n",
       " 'inches': 685,\n",
       " 'nicer': 686,\n",
       " 'fit.': 687,\n",
       " 'redoing': 688,\n",
       " 'looked': 689,\n",
       " 'proportion': 690,\n",
       " 'tigh': 691,\n",
       " 'The': 692,\n",
       " 'colors': 693,\n",
       " \"weren't\": 694,\n",
       " 'expected': 695,\n",
       " 'either.': 696,\n",
       " 'dark': 697,\n",
       " 'blue': 698,\n",
       " 'vibrant': 699,\n",
       " \"couldn't\": 700,\n",
       " 'anything': 701,\n",
       " 'thick': 702,\n",
       " 'movement': 703,\n",
       " 'end.': 704,\n",
       " 'goodhyouman': 705,\n",
       " 'shirts': 706,\n",
       " 'many': 707,\n",
       " 'compliments': 708,\n",
       " 'them.': 709,\n",
       " 'especially': 710,\n",
       " 'says': 711,\n",
       " 'forehead': 712,\n",
       " 'kisses': 713,\n",
       " 'underrated.': 714,\n",
       " 'hesitate.': 715,\n",
       " 'buy': 716,\n",
       " 'shirt.': 717,\n",
       " \"won't\": 718,\n",
       " 'sorry.....': 719,\n",
       " 'comfy': 720,\n",
       " 'classic': 721,\n",
       " 'balances': 722,\n",
       " 'quirky': 723,\n",
       " 'hand-knit': 724,\n",
       " 'beautiful': 725,\n",
       " 'practical': 726,\n",
       " 'cropped': 727,\n",
       " 'boxy': 728,\n",
       " 'part': 729,\n",
       " 'style,': 730,\n",
       " 'others': 731,\n",
       " 'mentioned,': 732,\n",
       " 'knit': 733,\n",
       " 'see-through.': 734,\n",
       " 'makes': 735,\n",
       " 'layering!': 736,\n",
       " 'having': 737,\n",
       " 'camisole': 738,\n",
       " 'showing': 739,\n",
       " 'underneath,': 740,\n",
       " 'wearing': 741,\n",
       " 'warm': 742,\n",
       " 'thin': 743,\n",
       " 'jacket': 744,\n",
       " 'Beautifully': 745,\n",
       " 'trend': 746,\n",
       " 'flared': 747,\n",
       " 'crop.': 748,\n",
       " 'cuter': 749,\n",
       " 'these!': 750,\n",
       " 'given': 751,\n",
       " 'online,': 752,\n",
       " 'person': 753,\n",
       " 'cuter!': 754,\n",
       " 'stripes': 755,\n",
       " 'brighter': 756,\n",
       " 'crop': 757,\n",
       " 'cute': 758,\n",
       " 'trend.': 759,\n",
       " 'brand': 760,\n",
       " 'always': 761,\n",
       " 'run': 762,\n",
       " \"5'8\": 763,\n",
       " '140lbs': 764,\n",
       " 'carry': 765,\n",
       " 'chubbiness': 766,\n",
       " 'belly.': 767,\n",
       " 'collarless': 768,\n",
       " 'navy': 769,\n",
       " 'blazer': 770,\n",
       " 'These': 771,\n",
       " 'better': 772,\n",
       " 'downside': 773,\n",
       " 'cleaned.': 774,\n",
       " 'months': 775,\n",
       " 'ago,': 776,\n",
       " 'finally': 777,\n",
       " 'order.': 778,\n",
       " 'huge': 779,\n",
       " 'disappointment.': 780,\n",
       " 'wasn&#39;t': 781,\n",
       " 'issue': 782,\n",
       " 'wool': 783,\n",
       " 'subpar.': 784,\n",
       " 'else': 785,\n",
       " 'mentioned': 786,\n",
       " '&quot;felted': 787,\n",
       " 'wool&quot;...i': 788,\n",
       " 'guess,': 789,\n",
       " 'call': 790,\n",
       " 'it?': 791,\n",
       " 'literally': 792,\n",
       " 'felt!': 793,\n",
       " 'thin,': 794,\n",
       " 'itchy,': 795,\n",
       " 'doesn&#39;t': 796,\n",
       " 'well,': 797,\n",
       " '(made': 798,\n",
       " 'china).': 799,\n",
       " 'sale,': 800,\n",
       " 'worth': 801,\n",
       " 'paid.': 802,\n",
       " 'neat': 803,\n",
       " 'soft.': 804,\n",
       " 'added': 805,\n",
       " 'bonus.': 806,\n",
       " 'needs': 807,\n",
       " 'underneath': 808,\n",
       " 'gaps.': 809,\n",
       " 'funky': 810,\n",
       " 'tank': 811,\n",
       " 'top,': 812,\n",
       " 'necklaces': 813,\n",
       " 'boots.': 814,\n",
       " 'cute!!': 815,\n",
       " \"Wouldn't\": 816,\n",
       " 'whim.': 817,\n",
       " 'love!!': 818,\n",
       " 'span': 819,\n",
       " 'seasons': 820,\n",
       " 'easily.': 821,\n",
       " 'while': 822,\n",
       " 'exciting': 823,\n",
       " 'design,': 824,\n",
       " 'tops.': 825,\n",
       " 'Just': 826,\n",
       " '(5\\'6\",': 827,\n",
       " '135,': 828,\n",
       " '4)': 829,\n",
       " 'mom': 830,\n",
       " '(5\\'3\",': 831,\n",
       " '130,': 832,\n",
       " '8)': 833,\n",
       " 'gorgeous': 834,\n",
       " 'draped,': 835,\n",
       " 'weight/warmth': 836,\n",
       " \"i'll\": 837,\n",
       " 'houston': 838,\n",
       " 'winter,': 839,\n",
       " 'polished': 840,\n",
       " 'snapped': 841,\n",
       " 'unsnapped.': 842,\n",
       " 'age-appropriate': 843,\n",
       " \"(60's)\": 844,\n",
       " \"(30's).\": 845,\n",
       " 'amazing': 846,\n",
       " 'skinny': 847,\n",
       " 'we': 848,\n",
       " 'gray': 849,\n",
       " 'photos.': 850,\n",
       " 'Super': 851,\n",
       " 'pull': 852,\n",
       " 'over.': 853,\n",
       " 'sizing': 854,\n",
       " 'accurate.': 855,\n",
       " 'stretch.': 856,\n",
       " 'Great': 857,\n",
       " 'casual': 858,\n",
       " 'flare.': 859,\n",
       " 'grey': 860,\n",
       " 'pilcro': 861,\n",
       " 'stet': 862,\n",
       " 'jeans.': 863,\n",
       " 'peplum': 864,\n",
       " 'cut': 865,\n",
       " 'shoulders': 866,\n",
       " 'neckline.': 867,\n",
       " 'Pretty': 868,\n",
       " 'worn': 869,\n",
       " 'slacks': 870,\n",
       " 'heels.': 871,\n",
       " 'colors,': 872,\n",
       " 'print,': 873,\n",
       " 'embroidery': 874,\n",
       " 'lovely.': 875,\n",
       " 'reasonably': 876,\n",
       " 'priced!': 877,\n",
       " 'top.': 878,\n",
       " 'unique': 879,\n",
       " 'ordinary.': 880,\n",
       " 'across': 881,\n",
       " 'chest.': 882,\n",
       " 'baby': 883,\n",
       " 'year': 884,\n",
       " 'nursing,': 885,\n",
       " 'why.': 886,\n",
       " 'again': 887,\n",
       " 'up.': 888,\n",
       " 'poncho': 889,\n",
       " 'plaid': 890,\n",
       " 'check': 891,\n",
       " 'sorbet': 892,\n",
       " '&': 893,\n",
       " 'cream': 894,\n",
       " 'turtleneck': 895,\n",
       " 'roll': 896,\n",
       " 'spring.': 897,\n",
       " 'buy!!': 898,\n",
       " 'First,': 899,\n",
       " 'thermal': 900,\n",
       " ',so': 901,\n",
       " 'naturally': 902,\n",
       " 'expect': 903,\n",
       " 'sheer,': 904,\n",
       " 'is.': 905,\n",
       " 'sheer': 906,\n",
       " 'prepared': 907,\n",
       " 'considering': 908,\n",
       " 'might': 909,\n",
       " 'walk': 910,\n",
       " 'house': 911,\n",
       " 'second,': 912,\n",
       " '0': 913,\n",
       " 'oversized': 914,\n",
       " '5\\'3\"': 915,\n",
       " 'pounds.': 916,\n",
       " 'want': 917,\n",
       " 'larger.': 918,\n",
       " 'along': 919,\n",
       " 'being': 920,\n",
       " 'stretched,': 921,\n",
       " 'mind': 922,\n",
       " 'case.': 923,\n",
       " 'finally,': 924,\n",
       " 'color.': 925,\n",
       " 'monitor': 926,\n",
       " 'shows': 927,\n",
       " 'colorful': 928,\n",
       " 'dot': 929,\n",
       " 'Tried': 930,\n",
       " 'today': 931,\n",
       " 'local': 932,\n",
       " 'bad': 933,\n",
       " 'picture': 934,\n",
       " 'model': 935,\n",
       " 'tucking': 936,\n",
       " 'ruching': 937,\n",
       " 'front.': 938,\n",
       " 'alternative': 939,\n",
       " 'plain': 940,\n",
       " 'tee': 941,\n",
       " 'priced': 942,\n",
       " 'retailer.': 943,\n",
       " '5\\'8\"\"': 944,\n",
       " 'generally': 945,\n",
       " '6,': 946,\n",
       " 'probably': 947,\n",
       " 'black!': 948,\n",
       " 'item': 949,\n",
       " 'online...': 950,\n",
       " 'mine': 951,\n",
       " 'seemed': 952,\n",
       " 'sale': 953,\n",
       " 'time.': 954,\n",
       " 'started': 955,\n",
       " 'fade.': 956,\n",
       " \"i'd\": 957,\n",
       " 'recommend': 958,\n",
       " 'comfortable.': 959,\n",
       " 'Very': 960,\n",
       " 'comfortable,': 961,\n",
       " 'good,': 962,\n",
       " \"fall...it's\": 963,\n",
       " 'roomy,': 964,\n",
       " 'warm,': 965,\n",
       " 'pops.': 966,\n",
       " 'Really': 967,\n",
       " 'top!': 968,\n",
       " 'collar': 969,\n",
       " 'bib': 970,\n",
       " 'unique,': 971,\n",
       " 'received': 972,\n",
       " 'lots': 973,\n",
       " 'questions': 974,\n",
       " 'rather': 975,\n",
       " \"would've\": 976,\n",
       " 'adorable.': 977,\n",
       " 'transition': 978,\n",
       " 'summer': 979,\n",
       " 'fall.': 980,\n",
       " 'purchase': 981,\n",
       " 'washed': 982,\n",
       " 'out.': 983,\n",
       " 'best': 984,\n",
       " 'blonde.': 985,\n",
       " 'brunette.': 986,\n",
       " 'different': 987,\n",
       " 'likely': 988,\n",
       " 'absolutely': 989,\n",
       " 'tee!': 990,\n",
       " 'favorite': 991,\n",
       " '5\\'7\",': 992,\n",
       " '140': 993,\n",
       " 'pounds': 994,\n",
       " 'either': 995,\n",
       " 'm': 996,\n",
       " 'snags': 997,\n",
       " 'soft': 998,\n",
       " 'unusual,': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                        X,\n",
    "                                        y.values.reshape(-1,1),\n",
    "                                        train_size   = 0.7,\n",
    "                                        random_state = 1234,\n",
    "                                        shuffle      = False\n",
    "                                    )\n",
    "\n",
    "# print('X_train', X_train.values)\n",
    "# print('X_test', X_test.values)\n",
    "# print('y_train', y_train)\n",
    "# print('y_test', y_test)\n",
    "\n",
    "#print('X.values.tolist()', X.values.tolist())\n",
    "\n",
    "#test = torch.tensor(y.values.tolist())\n",
    "\n",
    "# X_train = torch.tensor(X_train.values.astype(np.float32)) \n",
    "# X_test = torch.tensor(X_test.values.astype(np.float32)) \n",
    "\n",
    "# y_train = torch.tensor(y_train.values.astype(np.float32))\n",
    "# y_test = torch.tensor(y_test.values.astype(np.float32))\n",
    "\n",
    "# train_target = torch.tensor(train['Target'].values.astype(np.float32))\n",
    "# train = torch.tensor(train.drop('Target', axis = 1).values.astype(np.float32)) \n",
    "# train_tensor = data_utils.TensorDataset(train, train_target) \n",
    "# train_loader = data_utils.DataLoader(dataset = train_tensor, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "print(X_train[0], y_train[0])\n",
    "word_to_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "ceramic-words",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs tensor([0, 1, 2, 3, 4, 5, 4, 6])\n",
      "embeds tensor([[ 0.4107,  1.0144, -1.0657, -0.6897, -0.1951,  1.4534],\n",
      "        [-1.0985, -0.6816, -0.5365,  0.0429,  0.1207,  0.4357],\n",
      "        [ 0.8546, -0.8771,  1.0214,  0.1660,  0.4804, -1.0735],\n",
      "        [ 1.4899,  1.4295, -0.4465,  1.4641, -0.2803,  1.0421],\n",
      "        [ 3.2272,  0.4155,  0.5625, -0.4644, -1.0295,  0.9616],\n",
      "        [-0.1536,  0.1546,  0.6190, -2.7387,  0.3251,  1.1198],\n",
      "        [ 3.2272,  0.4155,  0.5625, -0.4644, -1.0295,  0.9616],\n",
      "        [-1.4809, -1.6705,  0.5626, -1.2437, -0.3058,  1.1479]])\n",
      "lstm_out tensor([[[-1.8970e-01, -6.6170e-02,  6.0442e-02,  3.7987e-02, -1.6331e-01,\n",
      "           8.9354e-02]],\n",
      "\n",
      "        [[-2.1501e-01, -1.4187e-02,  9.2862e-02,  2.5745e-02, -1.4446e-01,\n",
      "           1.6180e-01]],\n",
      "\n",
      "        [[ 2.1043e-01,  2.8561e-01, -3.8741e-02, -1.8480e-02, -9.2887e-02,\n",
      "           5.8461e-02]],\n",
      "\n",
      "        [[ 5.7229e-02,  4.7122e-01, -3.1438e-04,  1.2780e-02, -1.9538e-01,\n",
      "           2.1837e-02]],\n",
      "\n",
      "        [[ 5.8387e-03,  6.0352e-01, -3.5498e-02,  3.5211e-02, -1.2217e-01,\n",
      "          -1.7779e-02]],\n",
      "\n",
      "        [[-8.4713e-02,  1.3098e-01,  8.0293e-04, -1.2540e-01, -1.9970e-01,\n",
      "           6.8758e-02]],\n",
      "\n",
      "        [[-5.7160e-02,  5.2087e-01, -3.0640e-02,  8.9601e-03, -1.3477e-01,\n",
      "          -2.3486e-02]],\n",
      "\n",
      "        [[-1.5442e-01,  4.8149e-02,  3.6975e-02, -5.4842e-02, -1.8328e-01,\n",
      "           1.1099e-01]]])\n",
      "tag_space tensor([[ 0.4141, -0.1143,  0.2134, -0.3856,  0.3204],\n",
      "        [ 0.4345, -0.1214,  0.2598, -0.3897,  0.2877],\n",
      "        [ 0.3406, -0.1038,  0.2064, -0.3955,  0.0992],\n",
      "        [ 0.3367,  0.0426,  0.3240, -0.3521,  0.1243],\n",
      "        [ 0.3656,  0.0925,  0.3447, -0.3025,  0.1170],\n",
      "        [ 0.3238,  0.0228,  0.2541, -0.4144,  0.2006],\n",
      "        [ 0.3628,  0.1031,  0.3317, -0.3089,  0.1521],\n",
      "        [ 0.3737, -0.0399,  0.2553, -0.4072,  0.2487]])\n",
      "tag_scores tensor([[-1.3265, -1.8548, -1.5272, -2.1262, -1.4202],\n",
      "        [-1.3125, -1.8684, -1.4871, -2.1367, -1.4592],\n",
      "        [-1.3297, -1.7741, -1.4640, -2.0659, -1.5712],\n",
      "        [-1.3971, -1.6912, -1.4098, -2.0859, -1.6095],\n",
      "        [-1.3945, -1.6676, -1.4154, -2.0625, -1.6431],\n",
      "        [-1.3949, -1.6960, -1.4646, -2.1332, -1.5182],\n",
      "        [-1.4016, -1.6612, -1.4326, -2.0733, -1.6123],\n",
      "        [-1.3585, -1.7720, -1.4768, -2.1393, -1.4834]])\n",
      "torch.mean(tag_scores,0) tensor([-1.3644, -1.7482, -1.4597, -2.1029, -1.5396])\n",
      "['Absolutely', 'wonderful', '-', 'silky', 'and', 'sexy', 'and', 'comfortable']\n",
      "tensor([-1.3644, -1.7482, -1.4597, -2.1029, -1.5396])\n",
      "sentence ['Absolutely', 'wonderful', '-', 'silky', 'and', 'sexy', 'and', 'comfortable']\n",
      "current_ratings [4]\n",
      "embeds tensor([[ 0.4107,  1.0144, -1.0657, -0.6897, -0.1951,  1.4534],\n",
      "        [-1.0985, -0.6816, -0.5365,  0.0429,  0.1207,  0.4357],\n",
      "        [ 0.8546, -0.8771,  1.0214,  0.1660,  0.4804, -1.0735],\n",
      "        [ 1.4899,  1.4295, -0.4465,  1.4641, -0.2803,  1.0421],\n",
      "        [ 3.2272,  0.4155,  0.5625, -0.4644, -1.0295,  0.9616],\n",
      "        [-0.1536,  0.1546,  0.6190, -2.7387,  0.3251,  1.1198],\n",
      "        [ 3.2272,  0.4155,  0.5625, -0.4644, -1.0295,  0.9616],\n",
      "        [-1.4809, -1.6705,  0.5626, -1.2437, -0.3058,  1.1479]],\n",
      "       grad_fn=<EmbeddingBackward>)\n",
      "lstm_out tensor([[[-1.8970e-01, -6.6170e-02,  6.0442e-02,  3.7987e-02, -1.6331e-01,\n",
      "           8.9354e-02]],\n",
      "\n",
      "        [[-2.1501e-01, -1.4187e-02,  9.2862e-02,  2.5745e-02, -1.4446e-01,\n",
      "           1.6180e-01]],\n",
      "\n",
      "        [[ 2.1043e-01,  2.8561e-01, -3.8741e-02, -1.8480e-02, -9.2887e-02,\n",
      "           5.8461e-02]],\n",
      "\n",
      "        [[ 5.7229e-02,  4.7122e-01, -3.1438e-04,  1.2780e-02, -1.9538e-01,\n",
      "           2.1837e-02]],\n",
      "\n",
      "        [[ 5.8387e-03,  6.0352e-01, -3.5498e-02,  3.5211e-02, -1.2217e-01,\n",
      "          -1.7779e-02]],\n",
      "\n",
      "        [[-8.4713e-02,  1.3098e-01,  8.0293e-04, -1.2540e-01, -1.9970e-01,\n",
      "           6.8758e-02]],\n",
      "\n",
      "        [[-5.7160e-02,  5.2087e-01, -3.0640e-02,  8.9601e-03, -1.3477e-01,\n",
      "          -2.3486e-02]],\n",
      "\n",
      "        [[-1.5442e-01,  4.8149e-02,  3.6975e-02, -5.4842e-02, -1.8328e-01,\n",
      "           1.1099e-01]]], grad_fn=<StackBackward>)\n",
      "tag_space tensor([[ 0.4141, -0.1143,  0.2134, -0.3856,  0.3204],\n",
      "        [ 0.4345, -0.1214,  0.2598, -0.3897,  0.2877],\n",
      "        [ 0.3406, -0.1038,  0.2064, -0.3955,  0.0992],\n",
      "        [ 0.3367,  0.0426,  0.3240, -0.3521,  0.1243],\n",
      "        [ 0.3656,  0.0925,  0.3447, -0.3025,  0.1170],\n",
      "        [ 0.3238,  0.0228,  0.2541, -0.4144,  0.2006],\n",
      "        [ 0.3628,  0.1031,  0.3317, -0.3089,  0.1521],\n",
      "        [ 0.3737, -0.0399,  0.2553, -0.4072,  0.2487]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tag_scores tensor([[-1.3265, -1.8548, -1.5272, -2.1262, -1.4202],\n",
      "        [-1.3125, -1.8684, -1.4871, -2.1367, -1.4592],\n",
      "        [-1.3297, -1.7741, -1.4640, -2.0659, -1.5712],\n",
      "        [-1.3971, -1.6912, -1.4098, -2.0859, -1.6095],\n",
      "        [-1.3945, -1.6676, -1.4154, -2.0625, -1.6431],\n",
      "        [-1.3949, -1.6960, -1.4646, -2.1332, -1.5182],\n",
      "        [-1.4016, -1.6612, -1.4326, -2.0733, -1.6123],\n",
      "        [-1.3585, -1.7720, -1.4768, -2.1393, -1.4834]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "torch.mean(tag_scores,0) tensor([-1.3644, -1.7482, -1.4597, -2.1029, -1.5396], grad_fn=<MeanBackward1>)\n",
      "tag_scores tensor([-1.3644, -1.7482, -1.4597, -2.1029, -1.5396], grad_fn=<MeanBackward1>)\n",
      "aslkdmalksmdslakmdaslkmsadkl\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2 or more dimensions (got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-224-9d8e20020257>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;31m# parámetros por medio del optimizador.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m#loss = loss_function(tag_scores, targets.long()).float()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2379\u001b[0m     \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2380\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2381\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expected 2 or more dimensions (got {})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2383\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2 or more dimensions (got 1)"
     ]
    }
   ],
   "source": [
    "# Preparación de los datos \n",
    "def prepare_sequence(seq, to_ix):\n",
    "    # Prepara tensores de indices de palabras a partir de una oración.\n",
    "    # Parámetros:\n",
    "    #   seq: oración\n",
    "    #   to_ix: diccionario de palabras.\n",
    "    idxs = [to_ix[w] for w in seq]\n",
    "    #idxs = to_ix[seq]\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "# Entrenar el modelo \n",
    "\n",
    "# Valores antes de entrenar\n",
    "# El elemento i, j de la salida es la puntuación entre la etiqueta j para la palabra i.\n",
    "with torch.no_grad():\n",
    "    inputs = prepare_sequence(X_train[0], word_to_ix)\n",
    "    print('inputs', inputs)\n",
    "    tag_scores = model(inputs)\n",
    "    \n",
    "    print(X_train[0])\n",
    "    \n",
    "    # Clasificación    \n",
    "    print(tag_scores)\n",
    "\n",
    "# Corridas o épocas\n",
    "for epoch in range(500):  # definir epocas por fuera?       ## [N, D, N], [N, D, N]\n",
    "    for sentence, current_ratings in zip(X_train, y_train): ## [1], [2]\n",
    "        print('sentence', sentence)\n",
    "        print('current_ratings', current_ratings)\n",
    "        ## Paso 1. Pytorch acumula los gradientes.\n",
    "        # Es necesario limpiarlos\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Paso 2. Se preparan las entradas, es decir, se convierten a\n",
    "        # tensores de índices de palabras.\n",
    "        sentence_in = prepare_sequence(sentence, word_to_ix)\n",
    "        #print('current_ratings', current_ratings)\n",
    "        #targets = prepare_sequence(rating, ratings)\n",
    "\n",
    "        # Paso 3. Se genera la predicción (forward pass).\n",
    "        tag_scores = model(sentence_in)\n",
    "#         print('tag_scores', tag_scores)\n",
    "        targets = torch.tensor(current_ratings)\n",
    "        \n",
    "#         print('aslkdmalksmdslakmdaslkmsadkl')\n",
    "        #clone_vs_deepcopy(tag_scores)\n",
    "\n",
    "        # Paso 4. se calcula la pérdida, los gradientes, y se actualizan los \n",
    "        # parámetros por medio del optimizador.\n",
    "        #loss = loss_function(tag_scores, targets.long()).float()\n",
    "        loss = loss_function(tag_scores, targets)\n",
    "        print('loss', loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Despligue de la puntuación luego del entrenamiento\n",
    "with torch.no_grad():\n",
    "    inputs = prepare_sequence(training_data[0], word_to_ix)\n",
    "    tag_scores = model(inputs)\n",
    "   \n",
    "    print(\"Resultados luego del entrenamiento para la primera frase\")\n",
    "    # Las palabras en una oración se pueden etiquetar de tres formas.\n",
    "    # La primera oración tiene 4 palabras \"El perro come manzana\"\n",
    "    # por eso el tensor de salida tiene 4 elementos. \n",
    "    # Cada elemento es un vector de pesos que indica cuál etiqueta tiene más\n",
    "    # posibilidad de estar asociada a la palabra. Es decir hay que calcular \n",
    "    # la posición del valor máximo\n",
    "    print(tag_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sitting-pipeline",
   "metadata": {},
   "source": [
    "4. Evalúe el modelo resultante utilizando una matriz de confusión y métricas extraídas a partir de esta (ie. precisión, exhaustividad y F1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abstract-active",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "finnish-aaron",
   "metadata": {},
   "source": [
    "5. Genere y documente sus conclusiones (incluya al menos cuatro conclusionesimportantes). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stylish-investment",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "frozen-mission",
   "metadata": {},
   "source": [
    "Referencias\n",
    "----------------\n",
    "*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forbidden-modem",
   "metadata": {},
   "source": [
    "## B. Reconocimiento   de   nombres   de   entidades   (NER,   Name   EntityRecognition) con redes neuronales recurrentes utilizando Pytorch.\n",
    "\n",
    "El reconocimiento de nombres de entidades (NER)  es  el proceso  de identificar y categorizar elementos clave (ej. entidades) en el texto. Una entidad puede ser cualquier palabra o secuencia de palabras que se refieren a una persona, animal, sitio o cosa (ej.empresa, región geográfica, objeto). Cada entidad detectada se clasifica en una categoría predeterminada. Normalmente, NER se aborda como un problema de etiquetado de secuencias. Una explicación muy detallada de porqué es importante extraer entidades de los textos se encuentra en (Monge, 2020).\n",
    "\n",
    "Los algoritmos de extracción de entidades pueden únicamente detectar la presencia de una entidad y marcarla como tal o pueden detectar y clasificar cada entidad que encuentran.\n",
    "\n",
    "Ejemplo: En una oración como “arbusto de 2 m. flores lila.”.  Cada palabra representa un token donde “arbusto” y “flores” son los elementos de interés a marcar. El etiquetado “token inicial- token interno” es una forma común de indicar dónde comienzan y terminan las entidades. En el ejemplo anterior la etiqueta sería “B O O O B O” donde B representael inicio de la entidad y O cualquier otro token. Para la oración “botones florales rosados.” la etiqueta estaría dada por “B I O” donde “B” marca el token inicio de la entidad e “I” los otros tokens que son parte de esta, es decir “B I” delimita la entidad “botones florales”. \n",
    "\n",
    "Otra forma de marcar y etiquetar, es además de delimitar la entidad, asignar a esta la clase a la que corresponde, por ejemplo: empresa, ciudad, persona, entre otros. Para el presente ejercicio se va a utilizar este enfoque.\n",
    "\n",
    "Utilice los datos para reconocer y clasificar nombres de entidades compartidos en Kaggle por (Ranjan, 2020) para:\n",
    "\n",
    "1. Cargue y prepare los datos para ser introducidos a la red recurrente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "internal-nothing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence_ID</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>997</td>\n",
       "      <td>877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Sentence: 10821</td>\n",
       "      <td>['Grenada', 'was', 'seized', 'by', 'a', 'Marxi...</td>\n",
       "      <td>['NNP', 'POS', 'NNP', 'NNP', 'VBZ', '.']</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Sentence_ID                                               Word  \\\n",
       "count              1000                                               1000   \n",
       "unique             1000                                               1000   \n",
       "top     Sentence: 10821  ['Grenada', 'was', 'seized', 'by', 'a', 'Marxi...   \n",
       "freq                  1                                                  1   \n",
       "\n",
       "                                             POS  \\\n",
       "count                                       1000   \n",
       "unique                                       997   \n",
       "top     ['NNP', 'POS', 'NNP', 'NNP', 'VBZ', '.']   \n",
       "freq                                           3   \n",
       "\n",
       "                                                      Tag  \n",
       "count                                                1000  \n",
       "unique                                                877  \n",
       "top     ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  \n",
       "freq                                                   13  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nRowsRead = 1000\n",
    "\n",
    "# Se carga el archivo con los datos solicitados (defaultofcredit.csv) y se define\n",
    "# a la columna \"default_payment_next_month\" como la objetivo.\n",
    "ner = pd.read_csv('./data/NER_Dataset.csv', delimiter=',', nrows=nRowsRead)\n",
    "\n",
    "ner.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "corporate-reliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete missing observations for following variables\n",
    "# for x in [\"Clothing ID\",\"Age\",\"Title\",\"Review Text\",\"Rating\",\"Recommended IND\",\"Positive Feedback Count\",\"Division Name\",\"Department Name\",\"Class Name\"]:\n",
    "#     reviews = reviews[reviews[x].notnull()]\n",
    "    \n",
    "# X = reviews.drop(columns = reviews.columns[3:5])\n",
    "# X = pd.get_dummies(X)\n",
    "# y = reviews['Review Text']\n",
    "# y = [elem.split() for elem in y]\n",
    "\n",
    "#reviews['Rating'] = reviews[(reviews['Rating'] >= 1)  (reviews['Rating'] <= 5)]\n",
    "\n",
    "\n",
    "# ner[\"Word\"] = ner[\"Word\"].str.replace(r\"'\", '', regex=True)\n",
    "# ner[\"Word\"] = ner[\"Word\"].str.replace(r\"[\", '', regex=True)\n",
    "# ner[\"Word\"] = ner[\"Word\"].str.replace(r\"]\", '', regex=True)\n",
    "# ner[\"Word\"] = ner[\"Word\"].str.replace(r\" \", '', regex=True)\n",
    "\n",
    "# ner[\"Word\"] = ner[\"Word\"].str.replace(r\"'\", '', regex=True)\n",
    "# ner[\"Word\"] = ner[\"Word\"].str.replace(r\"[\", '', regex=True)\n",
    "# ner[\"Word\"] = ner[\"Word\"].str.replace(r\"]\", '', regex=True)\n",
    "# ner[\"Word\"] = ner[\"Word\"].str.replace(r\" \", '', regex=True)\n",
    "\n",
    "#ner[\"Word\"] = ner[\"Word\"].Series.str.replace('[', '', regex=True)\n",
    "\n",
    "for x in [\"Word\", \"Tag\"]:\n",
    "#     ner[x] = ner[x].str.replace(\"[\", '', 1, regex=True)\n",
    "#     ner[x] = ner[x][-1].str.replace(\"]\", '', 1, regex=True)\n",
    "    ner[x] = ner[x].str.replace(\"'\", '', regex=True)\n",
    "    ner[x] = ner[x].str.replace(\", \", ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "concerned-creature",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ner['Word']\n",
    "X = [elem[1:-1].split() for elem in X]\n",
    "# X[0] = X[0][1:]\n",
    "# X[-1] = X[0][1:]\n",
    "y = ner['Tag']\n",
    "y = [elem[1:-1].split() for elem in y]\n",
    "# y.pop(0)\n",
    "# y.pop()\n",
    "\n",
    "\n",
    "# def limpiar_datos(dataset):\n",
    "#     for i in range(len(dataset)):\n",
    "#         dataset[i].remove()\n",
    "    \n",
    "word_to_ix = {}\n",
    "for frase in X:\n",
    "#     if review not in word_to_ix:\n",
    "#         word_to_ix[review] = len(word_to_ix)\n",
    "    for palabra in frase:\n",
    "        if palabra not in word_to_ix:\n",
    "            word_to_ix[palabra] = len(word_to_ix)\n",
    "\n",
    "            \n",
    "etiquetas_a_indice = {'O':0,'B-geo':1,'B-gpe':2,'B-org':3,'B-nat':4,'B-art':5,'B-eve':6,'B-tim':7,'B-per':8,\n",
    "                      'I-geo':9,'I-gpe':10,'I-org':11,'I-nat':12,'I-art':13,'I-eve':14,'I-tim':15,'I-per':16}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "plain-balloon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B-geo', 'B-org', 'B-gpe', 'I-tim', 'B-tim', 'B-nat', 'I-art', 'O', 'B-eve', 'I-eve', 'I-nat', 'B-per', 'I-org', 'I-gpe', 'I-per', 'I-geo', 'B-art'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4783"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten = lambda t: [item for sublist in t for item in sublist]\n",
    "test = flatten(y)\n",
    "# print(test)\n",
    "myset = set(test)\n",
    "print(myset)\n",
    "len(word_to_ix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excited-happiness",
   "metadata": {},
   "source": [
    "2. Utilizando PyTorch defina una red recurrente LSTM para procesar, localizar y clasificar las entidades presentes en el texto (como la vista en clase). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "failing-place",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición del modelo\n",
    "\n",
    "# El modelo es una clase que debe heredar de nn.Module\n",
    "class LSTMTagger(nn.Module):\n",
    "    \n",
    "    # Incialización del modelo\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    " \n",
    "\n",
    "        # Primero se pasa la entrada a través de una capa Embedding. \n",
    "        # Esta capa construye una representación de los tokens de \n",
    "        # un texto donde las palabras que tienen el mismo significado \n",
    "        # tienen una representación similar.\n",
    "        \n",
    "        # Esta capa captura mejor el contexto y son espacialmente \n",
    "        # más eficientes que las representaciones vectoriales (one-hot vector).\n",
    "        # En Pytorch, se usa el módulo nn.Embedding para crear esta capa, \n",
    "        # que toma el tamaño del vocabulario y la longitud deseada del vector \n",
    "        # de palabras como entrada. \n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # El LSTM toma word_embeddings como entrada y genera estados ocultos\n",
    "        # con dimensionalidad hidden_dim.  \n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "\n",
    "        # La capa lineal mapea el espacio de estado oculto \n",
    "        # al espacio de etiquetas\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        # Pase hacia adelante de la red. \n",
    "        # Parámetros:\n",
    "        #    sentence: la oración a procesar\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
    "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "\n",
    "#         print('tag_space', tag_space)\n",
    "        \n",
    "        # Se utiliza softmax para devolver un peso por etiqueta\n",
    "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "#         print('tag_scores', tag_scores)\n",
    "        return tag_scores\n",
    "\n",
    "# Instanciación del modelo, definición de la función de pérdida y del optimizador   \n",
    "\n",
    "# Hiperparámetros de la red\n",
    "# Valores generalmente altos (32 o 64 dimensiones).\n",
    "# Se definen pequeños, para ver cómo cambian los pesos durante el entrenamiento.\n",
    "\n",
    "EMBEDDING_DIM = 6#34\n",
    "HIDDEN_DIM = 6#34\n",
    "\n",
    "# Instancia del modelo\n",
    "model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix), len(etiquetas_a_indice)) # len([1,2,3,4,5]))\n",
    "\n",
    "# Función de pérdida: Negative Log Likelihood Loss (NLLL). \n",
    "# Útil para problemas de clasificacion con C clases.\n",
    "loss_function = nn.NLLLoss()#nn.CrossEntropyLoss()#nn.NLLLoss()\n",
    "\n",
    "# Optimizador Stochastic Gradient Descent  \n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gross-walker",
   "metadata": {},
   "source": [
    "3. Separe las muestras en datos de entrenamiento y evaluación y entrene el modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "purple-afternoon",
   "metadata": {},
   "outputs": [],
   "source": [
    "proporcion = lambda : 0.7\n",
    "\n",
    "# Se randomizan las posiciones de las clases.\n",
    "random.shuffle(X, proporcion)\n",
    "random.shuffle(y, proporcion)\n",
    "\n",
    "indice = int(len(X)*0.3)\n",
    "\n",
    "X_train, y_train = X[indice:], y[indice:]\n",
    "X_test, y_test = X[:indice], y[:indice]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frank-prototype",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparación de los datos \n",
    "def prepare_sequence(seq, to_ix):\n",
    "    # Prepara tensores de indices de palabras a partir de una oración.\n",
    "    # Parámetros:\n",
    "    #   seq: oración\n",
    "    #   to_ix: diccionario de palabras.\n",
    "    idxs = [to_ix[w] for w in seq]\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "# Entrenar el modelo \n",
    "\n",
    "# Valores antes de entrenar\n",
    "# El elemento i, j de la salida es la puntuación entre la etiqueta j para la palabra i.\n",
    "with torch.no_grad():\n",
    "    inputs = prepare_sequence(X_train[0], word_to_ix)\n",
    "    \n",
    "#     print('inputs', inputs, inputs.size())\n",
    "    \n",
    "    tag_scores = model(inputs)\n",
    "    \n",
    "#     print(X_train[0])\n",
    "    \n",
    "    # Clasificación    \n",
    "#     print(tag_scores)\n",
    "\n",
    "# Corridas o épocas\n",
    "for epoch in range(100):  \n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(epoch)\n",
    "    \n",
    "    for sentence, etiqueta in zip(X_train, y_train):\n",
    "#         print('sentence', sentence)\n",
    "#         print('tags', etiqueta)\n",
    "        ## Paso 1. Pytorch acumula los gradientes.\n",
    "        # Es necesario limpiarlos\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Paso 2. Se preparan las entradas, es decir, se convierten a\n",
    "        # tensores de índices de palabras.\n",
    "        sentence_in = prepare_sequence(sentence, word_to_ix)\n",
    "        targets = prepare_sequence(etiqueta, etiquetas_a_indice)\n",
    "#         print('targets', targets)\n",
    "        \n",
    "        # Paso 3. Se genera la predicción (forward pass).\n",
    "        tag_scores = model(sentence_in)\n",
    "#         print('tag_scores', tag_scores)\n",
    "\n",
    "        # Paso 4. se calcula la pérdida, los gradientes, y se actualizan los \n",
    "        # parámetros por medio del optimizador.\n",
    "#         print('tag_scores', tag_scores, tag_scores.size())\n",
    "#         print('targets', targets)\n",
    "        loss = loss_function(tag_scores, targets)\n",
    "#         print('lossmljsmaLKMSALKmaslkMLKSAMlkmaldksmlkads\\nlksadmldksamlkdsmlakds', loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "optimum-participation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados luego del entrenamiento para la primera frase\n",
      "tensor([[-7.3905e-03, -1.0090e+01, -1.5211e+01, -1.1010e+01, -7.2639e+00,\n",
      "         -8.0030e+00, -9.4255e+00, -8.9662e+00, -1.3398e+01, -1.0983e+01,\n",
      "         -1.0065e+01, -6.0938e+00, -7.5411e+00, -7.1470e+00, -1.0219e+01,\n",
      "         -6.0572e+00, -9.9318e+00],\n",
      "        [-2.3842e-07, -2.5576e+01, -3.8041e+01, -2.8248e+01, -2.2967e+01,\n",
      "         -2.1987e+01, -2.5964e+01, -1.5428e+01, -3.4131e+01, -3.3666e+01,\n",
      "         -2.8596e+01, -2.4236e+01, -2.1589e+01, -2.4282e+01, -2.8306e+01,\n",
      "         -1.8465e+01, -3.2006e+01],\n",
      "        [-7.4237e+00, -3.1427e+00, -4.7707e+00, -5.8448e-01, -6.1850e+00,\n",
      "         -6.6674e+00, -6.3390e+00, -8.1915e+00, -9.6096e-01, -8.0502e+00,\n",
      "         -7.2502e+00, -9.0914e+00, -8.7334e+00, -7.3305e+00, -7.8715e+00,\n",
      "         -1.0492e+01, -9.2291e+00],\n",
      "        [-1.7134e+01, -1.3331e+01, -8.7627e+00, -6.9044e+00, -7.2531e+00,\n",
      "         -7.7772e+00, -8.5695e+00, -2.1454e+01, -6.9506e+00, -4.0762e+00,\n",
      "         -5.8616e+00, -7.2274e-01, -1.0269e+01, -5.7622e+00, -6.8226e+00,\n",
      "         -1.0088e+01, -7.1946e-01],\n",
      "        [-5.3388e-03, -1.0979e+01, -1.8219e+01, -9.1472e+00, -9.9432e+00,\n",
      "         -9.3374e+00, -9.6187e+00, -1.2347e+01, -1.3234e+01, -7.1505e+00,\n",
      "         -8.5837e+00, -6.4724e+00, -1.2116e+01, -8.2095e+00, -9.7622e+00,\n",
      "         -6.1642e+00, -1.0210e+01],\n",
      "        [-1.0939e-02, -9.9934e+00, -1.7520e+01, -1.3156e+01, -8.9375e+00,\n",
      "         -1.0826e+01, -9.5832e+00, -1.1489e+01, -1.5041e+01, -6.3569e+00,\n",
      "         -9.3655e+00, -6.7446e+00, -9.7863e+00, -6.9523e+00, -1.0016e+01,\n",
      "         -5.0377e+00, -9.7591e+00],\n",
      "        [-2.7060e-05, -1.7351e+01, -2.5599e+01, -1.3599e+01, -1.5366e+01,\n",
      "         -1.2007e+01, -1.6065e+01, -1.4752e+01, -2.1920e+01, -1.7861e+01,\n",
      "         -1.5402e+01, -1.3351e+01, -1.6741e+01, -1.4651e+01, -1.6268e+01,\n",
      "         -1.1009e+01, -2.0690e+01],\n",
      "        [ 0.0000e+00, -2.6460e+01, -4.0858e+01, -2.0557e+01, -2.7925e+01,\n",
      "         -2.3023e+01, -2.6683e+01, -2.3816e+01, -3.0921e+01, -2.8104e+01,\n",
      "         -2.5762e+01, -2.9403e+01, -3.0628e+01, -2.7091e+01, -2.7245e+01,\n",
      "         -2.1959e+01, -3.6305e+01],\n",
      "        [-1.1921e-07, -1.8901e+01, -3.3786e+01, -2.0210e+01, -2.3699e+01,\n",
      "         -2.2331e+01, -2.2592e+01, -1.6743e+01, -2.6720e+01, -2.3821e+01,\n",
      "         -2.3641e+01, -2.7386e+01, -2.5192e+01, -2.3102e+01, -2.4626e+01,\n",
      "         -1.8364e+01, -3.2713e+01],\n",
      "        [-4.1603e-05, -1.3177e+01, -2.2778e+01, -1.1155e+01, -1.6337e+01,\n",
      "         -1.4546e+01, -1.6768e+01, -1.0611e+01, -1.5989e+01, -2.2719e+01,\n",
      "         -1.8724e+01, -2.1338e+01, -1.7794e+01, -1.8131e+01, -1.9197e+01,\n",
      "         -1.6442e+01, -2.5396e+01],\n",
      "        [ 0.0000e+00, -2.4389e+01, -4.0494e+01, -2.4895e+01, -2.6465e+01,\n",
      "         -2.5362e+01, -2.5255e+01, -2.1158e+01, -3.0827e+01, -2.4762e+01,\n",
      "         -2.5509e+01, -2.6810e+01, -2.8221e+01, -2.5048e+01, -2.6758e+01,\n",
      "         -1.9246e+01, -3.1743e+01],\n",
      "        [ 0.0000e+00, -2.2363e+01, -3.8800e+01, -2.4110e+01, -2.6595e+01,\n",
      "         -2.5582e+01, -2.5302e+01, -1.9924e+01, -3.0396e+01, -2.5359e+01,\n",
      "         -2.6064e+01, -2.9625e+01, -2.8132e+01, -2.5467e+01, -2.7164e+01,\n",
      "         -2.0022e+01, -3.4682e+01],\n",
      "        [-2.0656e-02, -1.1579e+01, -2.1430e+01, -1.1160e+01, -1.5477e+01,\n",
      "         -1.0305e+01, -1.6178e+01, -3.8936e+00, -2.3014e+01, -2.5193e+01,\n",
      "         -1.8537e+01, -1.7541e+01, -1.5387e+01, -1.6978e+01, -1.8868e+01,\n",
      "         -1.1162e+01, -2.9506e+01],\n",
      "        [-1.4368e-03, -7.8185e+00, -1.9274e+01, -9.0295e+00, -1.4125e+01,\n",
      "         -1.1631e+01, -1.2017e+01, -7.7493e+00, -1.7651e+01, -1.1433e+01,\n",
      "         -1.2299e+01, -1.4309e+01, -1.6011e+01, -1.2518e+01, -1.3652e+01,\n",
      "         -7.7151e+00, -2.2002e+01],\n",
      "        [ 0.0000e+00, -2.4244e+01, -4.0822e+01, -2.5675e+01, -2.7169e+01,\n",
      "         -2.6474e+01, -2.5914e+01, -2.1844e+01, -3.1400e+01, -2.4954e+01,\n",
      "         -2.6261e+01, -2.8902e+01, -2.8830e+01, -2.5650e+01, -2.7449e+01,\n",
      "         -2.0092e+01, -3.3464e+01],\n",
      "        [-3.1783e+01, -5.4676e+00, -1.5844e-02, -4.7478e+00, -1.2337e+01,\n",
      "         -1.3081e+01, -1.1235e+01, -1.8878e+01, -6.0730e+00, -7.6753e+00,\n",
      "         -1.0791e+01, -1.3842e+01, -1.5463e+01, -1.1607e+01, -1.1712e+01,\n",
      "         -1.7545e+01, -1.4854e+01],\n",
      "        [-4.9534e+00, -6.9366e+00, -5.7840e+00, -1.3742e+00, -3.3044e+00,\n",
      "         -3.4697e+00, -4.6910e+00, -1.5019e+01, -2.7201e+00, -1.4939e+00,\n",
      "         -2.5856e+00, -2.5374e+00, -6.0017e+00, -2.3469e+00, -3.3155e+00,\n",
      "         -6.4399e+00, -2.5510e+00],\n",
      "        [-4.3272e-05, -2.2538e+01, -2.6541e+01, -1.0346e+01, -1.4658e+01,\n",
      "         -1.1983e+01, -1.6537e+01, -2.3811e+01, -1.3635e+01, -1.7979e+01,\n",
      "         -1.4341e+01, -1.3582e+01, -1.7977e+01, -1.5210e+01, -1.5271e+01,\n",
      "         -1.6906e+01, -1.3991e+01],\n",
      "        [-3.9815e-05, -1.3853e+01, -2.0622e+01, -1.0614e+01, -1.2814e+01,\n",
      "         -1.2483e+01, -1.4075e+01, -1.3964e+01, -1.2816e+01, -1.6867e+01,\n",
      "         -1.4665e+01, -1.5441e+01, -1.4550e+01, -1.3751e+01, -1.5131e+01,\n",
      "         -1.3974e+01, -1.6968e+01]])\n"
     ]
    }
   ],
   "source": [
    "# Despligue de la puntuación luego del entrenamiento\n",
    "with torch.no_grad():\n",
    "    inputs = prepare_sequence(X_train[0], word_to_ix)\n",
    "    tag_scores = model(inputs)\n",
    "   \n",
    "    print(\"Resultados luego del entrenamiento para la primera frase\")\n",
    "    # Las palabras en una oración se pueden etiquetar de tres formas.\n",
    "    # La primera oración tiene 4 palabras \"El perro come manzana\"\n",
    "    # por eso el tensor de salida tiene 4 elementos. \n",
    "    # Cada elemento es un vector de pesos que indica cuál etiqueta tiene más\n",
    "    # posibilidad de estar asociada a la palabra. Es decir hay que calcular \n",
    "    # la posición del valor máximo\n",
    "    print(tag_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dirty-generic",
   "metadata": {},
   "source": [
    "4. Evalúe el modelo resultante. Utilice la métrica propuesta por el InternationalWorkshop on Semantic Evaluation (SemEval), una explicación básica está disponible en (Batista, 2018).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "unnecessary-dealing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etiquetas\n",
      "{'O': 0, 'B-geo': 1, 'B-gpe': 2, 'B-org': 3, 'B-nat': 4, 'B-art': 5, 'B-eve': 6, 'B-tim': 7, 'B-per': 8, 'I-geo': 9, 'I-gpe': 10, 'I-org': 11, 'I-nat': 12, 'I-art': 13, 'I-eve': 14, 'I-tim': 15, 'I-per': 16}\n",
      "FRASE\n",
      "La frase original ['Thousands', 'of', 'demonstrators', 'have', 'marched', 'through', 'London', 'to', 'protest', 'the', 'war', 'in', 'Iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'British', 'troops', 'from', 'that', 'country', '.']\n",
      "La frase original preprocesada tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14,  9, 15,  1,\n",
      "        16, 17, 18, 19, 20, 21])\n",
      "Salida del modelo tensor([[ 0.0000e+00, -2.8718e+01, -4.3295e+01, -2.6295e+01, -2.7822e+01,\n",
      "         -2.4183e+01, -2.8142e+01, -2.2482e+01, -3.5736e+01, -3.1194e+01,\n",
      "         -2.8209e+01, -2.7903e+01, -2.8850e+01, -2.7250e+01, -2.9109e+01,\n",
      "         -2.0848e+01, -3.5956e+01],\n",
      "        [ 0.0000e+00, -2.3958e+01, -3.7577e+01, -1.9667e+01, -2.7258e+01,\n",
      "         -2.2015e+01, -2.7311e+01, -1.9343e+01, -3.0770e+01, -3.3702e+01,\n",
      "         -2.8241e+01, -3.3380e+01, -2.8695e+01, -2.8341e+01, -2.8976e+01,\n",
      "         -2.3762e+01, -4.1553e+01],\n",
      "        [ 0.0000e+00, -2.0421e+01, -3.2235e+01, -2.0570e+01, -2.2557e+01,\n",
      "         -2.2767e+01, -2.4243e+01, -1.7352e+01, -2.2855e+01, -3.0807e+01,\n",
      "         -2.6956e+01, -3.1472e+01, -2.3177e+01, -2.4920e+01, -2.6890e+01,\n",
      "         -2.3878e+01, -3.3165e+01],\n",
      "        [-9.5367e-07, -1.9221e+01, -3.3361e+01, -2.4499e+01, -2.3301e+01,\n",
      "         -2.4181e+01, -2.4805e+01, -1.3878e+01, -2.7822e+01, -3.1308e+01,\n",
      "         -2.8462e+01, -3.1520e+01, -2.2687e+01, -2.5045e+01, -2.8230e+01,\n",
      "         -2.1476e+01, -3.5732e+01],\n",
      "        [-9.8907e-04, -9.4180e+00, -1.9553e+01, -8.5414e+00, -1.4633e+01,\n",
      "         -1.1763e+01, -1.3878e+01, -7.2720e+00, -1.6176e+01, -1.8039e+01,\n",
      "         -1.5316e+01, -1.7561e+01, -1.6197e+01, -1.5202e+01, -1.6165e+01,\n",
      "         -1.1807e+01, -2.4346e+01],\n",
      "        [-1.1921e-07, -1.8637e+01, -2.9897e+01, -1.9412e+01, -2.0953e+01,\n",
      "         -2.1471e+01, -2.2581e+01, -1.6522e+01, -2.1559e+01, -2.8211e+01,\n",
      "         -2.5110e+01, -2.9658e+01, -2.1540e+01, -2.2967e+01, -2.5051e+01,\n",
      "         -2.2163e+01, -3.1298e+01],\n",
      "        [-1.5002e+01, -1.0213e-02, -6.7423e+00, -8.8802e+00, -1.3167e+01,\n",
      "         -1.4118e+01, -1.1032e+01, -4.7361e+00, -1.3710e+01, -1.0668e+01,\n",
      "         -1.3654e+01, -1.8018e+01, -1.3986e+01, -1.2363e+01, -1.4323e+01,\n",
      "         -1.0862e+01, -2.4132e+01],\n",
      "        [ 0.0000e+00, -3.1496e+01, -4.7975e+01, -3.4488e+01, -2.9636e+01,\n",
      "         -3.1602e+01, -3.0879e+01, -2.6056e+01, -3.5675e+01, -3.2262e+01,\n",
      "         -3.2342e+01, -3.1961e+01, -2.9969e+01, -2.9379e+01, -3.2719e+01,\n",
      "         -2.4707e+01, -3.3747e+01],\n",
      "        [-1.7055e-03, -8.6889e+00, -1.8044e+01, -7.6515e+00, -1.4030e+01,\n",
      "         -1.1430e+01, -1.3770e+01, -6.8647e+00, -1.4545e+01, -1.9102e+01,\n",
      "         -1.5619e+01, -1.8804e+01, -1.5451e+01, -1.5289e+01, -1.6237e+01,\n",
      "         -1.2921e+01, -2.4803e+01],\n",
      "        [-2.5868e-05, -1.6929e+01, -2.4106e+01, -1.2449e+01, -1.4430e+01,\n",
      "         -1.1317e+01, -1.5705e+01, -1.4255e+01, -1.9712e+01, -1.8935e+01,\n",
      "         -1.5436e+01, -1.3586e+01, -1.5746e+01, -1.4535e+01, -1.6088e+01,\n",
      "         -1.1971e+01, -1.9944e+01],\n",
      "        [-8.3936e-04, -1.3235e+01, -2.5722e+01, -1.9590e+01, -1.6626e+01,\n",
      "         -1.6876e+01, -1.7415e+01, -7.0994e+00, -2.4662e+01, -2.1847e+01,\n",
      "         -2.0341e+01, -1.8362e+01, -1.5902e+01, -1.6902e+01, -2.0484e+01,\n",
      "         -1.1391e+01, -2.5601e+01],\n",
      "        [-5.7220e-06, -1.5622e+01, -3.3159e+01, -1.9941e+01, -2.5904e+01,\n",
      "         -2.0936e+01, -2.3506e+01, -1.2127e+01, -3.5104e+01, -2.5057e+01,\n",
      "         -2.4540e+01, -3.0549e+01, -2.6452e+01, -2.4028e+01, -2.5705e+01,\n",
      "         -1.5220e+01, -4.3740e+01],\n",
      "        [-1.6761e+01, -4.4557e-02, -8.0213e+00, -1.1149e+01, -1.5044e+01,\n",
      "         -1.3906e+01, -1.2268e+01, -3.1480e+00, -2.1364e+01, -1.1322e+01,\n",
      "         -1.4554e+01, -1.7836e+01, -1.5072e+01, -1.2921e+01, -1.5384e+01,\n",
      "         -8.1868e+00, -2.9479e+01],\n",
      "        [-1.6689e-06, -1.7285e+01, -3.0563e+01, -1.7284e+01, -2.0069e+01,\n",
      "         -1.8323e+01, -1.8656e+01, -1.5372e+01, -2.4090e+01, -1.8040e+01,\n",
      "         -1.8684e+01, -1.9302e+01, -2.1981e+01, -1.8564e+01, -1.9998e+01,\n",
      "         -1.3432e+01, -2.5230e+01],\n",
      "        [-3.2050e-04, -1.8342e+01, -3.0527e+01, -2.2653e+01, -2.0365e+01,\n",
      "         -1.8092e+01, -2.2870e+01, -8.0462e+00, -3.1245e+01, -3.3043e+01,\n",
      "         -2.6625e+01, -2.4614e+01, -1.8548e+01, -2.2396e+01, -2.6178e+01,\n",
      "         -1.6195e+01, -3.5019e+01],\n",
      "        [-2.5034e-05, -1.7428e+01, -2.6317e+01, -1.4013e+01, -1.6158e+01,\n",
      "         -1.2277e+01, -1.6635e+01, -1.4316e+01, -2.3487e+01, -1.8621e+01,\n",
      "         -1.6020e+01, -1.4132e+01, -1.7429e+01, -1.5313e+01, -1.6931e+01,\n",
      "         -1.0948e+01, -2.2546e+01],\n",
      "        [-1.8261e-04, -1.2396e+01, -2.3585e+01, -1.6764e+01, -1.7086e+01,\n",
      "         -1.6455e+01, -1.8298e+01, -8.6348e+00, -2.2732e+01, -2.4096e+01,\n",
      "         -2.1206e+01, -2.3708e+01, -1.6600e+01, -1.8254e+01, -2.1122e+01,\n",
      "         -1.4863e+01, -3.0270e+01],\n",
      "        [-5.9605e-07, -1.8154e+01, -2.8007e+01, -1.5469e+01, -1.9660e+01,\n",
      "         -1.6007e+01, -2.0821e+01, -1.5124e+01, -2.4437e+01, -2.6356e+01,\n",
      "         -2.1730e+01, -2.4682e+01, -2.0461e+01, -2.0621e+01, -2.2092e+01,\n",
      "         -1.7714e+01, -3.1945e+01],\n",
      "        [-2.6276e+01, -5.1700e+00, -3.8273e-01, -1.2567e+00, -1.0463e+01,\n",
      "         -9.6687e+00, -9.6433e+00, -1.5646e+01, -3.6017e+00, -8.9015e+00,\n",
      "         -9.3467e+00, -1.1380e+01, -1.3840e+01, -1.0707e+01, -1.0311e+01,\n",
      "         -1.5990e+01, -1.3019e+01],\n",
      "        [-1.8166e-04, -2.2365e+01, -2.6209e+01, -1.0513e+01, -1.3418e+01,\n",
      "         -1.1944e+01, -1.5035e+01, -2.4580e+01, -1.1823e+01, -1.4363e+01,\n",
      "         -1.2409e+01, -1.0377e+01, -1.7076e+01, -1.3341e+01, -1.3516e+01,\n",
      "         -1.5323e+01, -9.2125e+00],\n",
      "        [-3.7619e-01, -3.4652e+00, -8.4121e+00, -1.9015e+00, -5.2916e+00,\n",
      "         -6.2192e+00, -4.9922e+00, -7.9401e+00, -2.5541e+00, -3.8807e+00,\n",
      "         -5.0913e+00, -6.4247e+00, -7.8762e+00, -5.0402e+00, -5.9937e+00,\n",
      "         -6.3683e+00, -6.6556e+00],\n",
      "        [ 0.0000e+00, -2.8586e+01, -4.4742e+01, -2.8842e+01, -2.8638e+01,\n",
      "         -2.8850e+01, -2.8294e+01, -2.5876e+01, -3.2372e+01, -2.7566e+01,\n",
      "         -2.8514e+01, -3.0297e+01, -3.0301e+01, -2.7524e+01, -2.9526e+01,\n",
      "         -2.2958e+01, -3.2783e+01],\n",
      "        [-1.3113e-06, -1.7046e+01, -2.7035e+01, -2.1743e+01, -1.7933e+01,\n",
      "         -1.9532e+01, -2.1067e+01, -1.3672e+01, -2.3901e+01, -2.7089e+01,\n",
      "         -2.4136e+01, -2.6124e+01, -1.6815e+01, -1.9721e+01, -2.3472e+01,\n",
      "         -1.8400e+01, -2.9422e+01],\n",
      "        [ 0.0000e+00, -3.3447e+01, -5.0384e+01, -3.3101e+01, -3.3176e+01,\n",
      "         -3.3897e+01, -3.4147e+01, -2.9024e+01, -3.4872e+01, -3.7510e+01,\n",
      "         -3.5747e+01, -3.9671e+01, -3.4358e+01, -3.4103e+01, -3.6177e+01,\n",
      "         -3.0839e+01, -4.0256e+01]])\n",
      "Valores máximos e índices (tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00, -9.5367e-07, -9.8907e-04,\n",
      "        -1.1921e-07, -1.0213e-02,  0.0000e+00, -1.7055e-03, -2.5868e-05,\n",
      "        -8.3936e-04, -5.7220e-06, -4.4557e-02, -1.6689e-06, -3.2050e-04,\n",
      "        -2.5034e-05, -1.8261e-04, -5.9605e-07, -3.8273e-01, -1.8166e-04,\n",
      "        -3.7619e-01,  0.0000e+00, -1.3113e-06,  0.0000e+00]), tensor([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0]))\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "# Probar el modelo\n",
    "\n",
    "# Funciones utilitarias\n",
    "\n",
    "def max_values(x):\n",
    "    # Retorna el valor máximo y en índice o la posición del valor en un vector x.\n",
    "    # Parámetros: \n",
    "    #    x: vector con los datos. \n",
    "    # Salida: \n",
    "    #    out: valor \n",
    "    #    inds: índice\n",
    "    out, inds = torch.max(x,dim=1)   \n",
    "    return out, inds\n",
    "\n",
    "def test_examples(test_data):\n",
    "\n",
    "   with torch.no_grad():\n",
    "      inputs = prepare_sequence(test_data, word_to_ix)\n",
    "      tag_scores = model(inputs)\n",
    "    \n",
    " \n",
    "   print(\"FRASE\") \n",
    "   print(\"La frase original\", test_data)    \n",
    "   print(\"La frase original preprocesada\", inputs)\n",
    "   print(\"Salida del modelo\", tag_scores)\n",
    "   print(\"Valores máximos e índices\", max_values(tag_scores))    \n",
    "    \n",
    "\n",
    "#print(\"Índice de palabras\")\n",
    "#print(\"word_to_idx\", word_to_ix)\n",
    "\n",
    "print(\"Etiquetas\")\n",
    "print(etiquetas_a_indice)\n",
    "\n",
    "#Frase 1\n",
    "# Las palabras en una oración se pueden etiquetar de tres formas.\n",
    "# La primera oración tiene 3 palabras \"El perro juega\"\n",
    "# por eso el tensor de salida tiene 3 elementos. \n",
    "# Cada elemento es un vector de pesos que indica cuál etiqueta tiene más\n",
    "# posibilidad de estar asociada a la palabra. Es decir hay que calcular \n",
    "# la posición del valor máximo. \n",
    "#   Ejemplo 1: \"El perro juega\" [\"DET\", \"NN\", \"V\"]\n",
    "# Ejemplo: 0, 1, 2 {\"DET\": 0, \"NN\": 1, \"V\": 2} => DET, NN, V \n",
    "test_examples(X_test[0])\n",
    "\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beginning-court",
   "metadata": {},
   "source": [
    "5. Genere   y   documente   sus   conclusiones   (incluya   al   menos   cuatro conclusiones importantes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alert-textbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expressed-vietnamese",
   "metadata": {},
   "source": [
    "Referencias\n",
    "----------------\n",
    "*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
